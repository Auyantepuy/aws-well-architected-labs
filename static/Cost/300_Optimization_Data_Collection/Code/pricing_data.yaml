AWSTemplateFormatVersion: '2010-09-09'
Description: Retrieves Pricing data
Parameters:
  DatabaseName:
    Type: String
    Description: Name of the Athena database to be created to hold lambda information
    Default: optimization_data
  DestinationBucket:
    Type: String
    Description: Name of the S3 Bucket to hold data information
    AllowedPattern: (?=^.{3,63}$)(?!^(\d+\.)+\d+$)(^(([a-z0-9]|[a-z0-9][a-z0-9\-]*[a-z0-9])\.)*([a-z0-9]|[a-z0-9][a-z0-9\-]*[a-z0-9])$)
  DestinationBucketARN:
    Type: String
    Description: ARN of the S3 Bucket that exists or needs to be created to hold rightsizing information
  CFDataName:
    Type: String
    Description: The name of what this cf is doing.
    Default: pricing
  RolePrefix:
    Type: String
    Description: This prefix will be placed in front of all roles created. Note you may wish to add a dash at the end to make more readable
  Schedule:
    Type: String
    Default: "cron(30 12 L * ? *)"
    Description: Cloud watch event Schedule to trigger the lambda 
Outputs:
  LambdaRoleARN:
    Description: Role for Lambda execution of lambda data.
    Value:
      Fn::GetAtt:
        - LambdaRole
        - Arn
Resources:
  LambdaRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "${RolePrefix}Lambda-Role-${CFDataName}"
      AssumeRolePolicyDocument:
        Statement:
          - Action:
              - sts:AssumeRole
            Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
        Version: 2012-10-17
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AWSLambdaExecute
      Path: /
      Policies:
        - PolicyName: !Sub "${CFDataName}-Access"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action:
                  - "s3:PutObject"
                  - "s3:ListBucket"
                  - "s3:GetBucketLocation"
                Resource: !Ref  DestinationBucketARN
              - Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                  - "logs:DescribeLogStreams"
                Resource: "arn:aws:logs:*:*:*"
  EC2LambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub "${CFDataName}-EC2-Lambda-Function"
      Description: !Sub "LambdaFunction to retrieve ${CFDataName}"
      Runtime: python3.8
      Architectures: [arm64]
      Code:
        ZipFile: |
          #Author Stephanie Gooch 2021
          # Function to download EC2 pricing
          # Please reachout to costoptimization@amazon.com if there's any comments or suggestions

          import json
          import boto3
          import urllib3
          import urllib.request
          import os
          import logging

          def lambda_handler(event, context):

              s3=boto3.resource('s3')
              http=urllib3.PoolManager()

              url = 'https://pricing.us-east-1.amazonaws.com/offers/v1.0/aws/AmazonEC2/current/index.csv'
              s3Bucket =  os.environ["BUCKET_NAME"]
              key = f'{os.environ["DEST_PREFIX"]}/ec2/ec2_prices.csv'

              urllib.request.urlopen(url)   #Provide URL
              s3.meta.client.upload_fileobj(http.request('GET', url, preload_content=False), s3Bucket, key)

              region_data(s3Bucket, s3)

              return {
                  'statusCode': 200,
                  'body': json.dumps('YAY!')
              }
          def region_data(s3Bucket, s3):

            #Create a Source Dictionary That Specifies Bucket Name and Key Name of the Object to Be Copied
            copy_source = {
                'Bucket': 'aws-well-architected-labs',
                'Key': 'Cost/Labs/300_Optimization_Data_Collection/Region/regions.csv'
            }
            
            bucket = s3.Bucket(s3Bucket)
            
            bucket.copy(copy_source, 'pricing/region/regions.csv')
            
            # Printing the Information That the File Is Copied.
            print('Single File is copied')


      Handler: 'index.lambda_handler'
      MemorySize: 2880
      Timeout: 300
      Role:
        Fn::GetAtt:
          - LambdaRole
          - Arn
      Environment:
        Variables:
          BUCKET_NAME:
            !Ref DestinationBucket
          ACCOUNT_ID: AWS::AccountId
          DEST_PREFIX: !Ref CFDataName
  CloudWatchTrigger:
    Type: AWS::Events::Rule
    Properties:
      Description: Weekly Notification Event for lambda data
      Name: !Sub "${CFDataName}-Weekly-Scheduler"
      ScheduleExpression: !Ref Schedule
      State: ENABLED
      Targets:
        - Arn:
            Fn::GetAtt:
              - EC2LambdaFunction
              - Arn
          Id: WeeklyTriggerForEC2Pricing
        - Arn:
            Fn::GetAtt:
              - RDSLambdaFunction
              - Arn
          Id: WeeklyTriggerForRDSPricing


  EC2EventPermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName:  
          Fn::GetAtt:
              - EC2LambdaFunction
              - Arn
      Action: lambda:InvokeFunction
      Principal: events.amazonaws.com
      SourceAccount: !Ref 'AWS::AccountId'
      SourceArn: !GetAtt CloudWatchTrigger.Arn
  RDSEventPermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName:  
          Fn::GetAtt:
              - RDSLambdaFunction
              - Arn
      Action: lambda:InvokeFunction
      Principal: events.amazonaws.com
      SourceAccount: !Ref 'AWS::AccountId'
      SourceArn: !GetAtt CloudWatchTrigger.Arn
  
  AthenaRegionTable:
    Type: AWS::Athena::NamedQuery
    Properties:
      Database: !Ref DatabaseName
      Description: Provides a summary view of the lambda data
      Name: region_names
      QueryString: !Sub
        "CREATE EXTERNAL TABLE 'region_names'(
        'region' string, 
        'regionname' string, 
        'endpoint' string, 
        'protocol' string)
      ROW FORMAT DELIMITED 
        FIELDS TERMINATED BY ',' 
      STORED AS INPUTFORMAT 
        'org.apache.hadoop.mapred.TextInputFormat' 
      OUTPUTFORMAT 
        'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
      LOCATION
        's3://${DestinationBucket}/pricing/region'
      TBLPROPERTIES (
        'has_encrypted_data'='false', 
        'skip.header.line.count'='1', 
        'transient_lastDdlTime'='1611498146')"  
  AthenaEC2PricingTable:
    Type: AWS::Athena::NamedQuery
    Properties:
      Database: !Ref DatabaseName
      Description: Provides a summary view of the lambda data
      Name: ec2_pricing_table
      QueryString: !Sub
        "CREATE EXTERNAL TABLE `ec2_global_pricelist`(
  `sku` string COMMENT 'from deserializer', 
  `offertermcode` string COMMENT 'from deserializer', 
  `ratecode` string COMMENT 'from deserializer', 
  `termtype` string COMMENT 'from deserializer', 
  `pricedescription` string COMMENT 'from deserializer', 
  `effectivedate` string COMMENT 'from deserializer', 
  `startingrange` string COMMENT 'from deserializer', 
  `endingrange` string COMMENT 'from deserializer', 
  `unit` string COMMENT 'from deserializer', 
  `priceperunit` string COMMENT 'from deserializer', 
  `currency` string COMMENT 'from deserializer', 
  `leasecontractlength` string COMMENT 'from deserializer', 
  `purchaseoption` string COMMENT 'from deserializer', 
  `offeringclass` string COMMENT 'from deserializer', 
  `productfamily` string COMMENT 'from deserializer', 
  `servicecode` string COMMENT 'from deserializer', 
  `location` string COMMENT 'from deserializer', 
  `locationtype` string COMMENT 'from deserializer', 
  `instancetype` string COMMENT 'from deserializer', 
  `currentgeneration` string COMMENT 'from deserializer', 
  `instancefamily` string COMMENT 'from deserializer', 
  `vcpu` string COMMENT 'from deserializer', 
  `physicalprocessor` string COMMENT 'from deserializer', 
  `clockspeed` string COMMENT 'from deserializer', 
  `memory` string COMMENT 'from deserializer', 
  `storage` string COMMENT 'from deserializer', 
  `networkperformance` string COMMENT 'from deserializer', 
  `processorarchitecture` string COMMENT 'from deserializer', 
  `storagemedia` string COMMENT 'from deserializer', 
  `volumetype` string COMMENT 'from deserializer', 
  `maxvolumesize` string COMMENT 'from deserializer', 
  `maxiops/volume` string COMMENT 'from deserializer', 
  `maxiopsburstperformance` string COMMENT 'from deserializer', 
  `maxthroughput/volume` string COMMENT 'from deserializer', 
  `provisioned` string COMMENT 'from deserializer', 
  `tenancy` string COMMENT 'from deserializer', 
  `ebsoptimized` string COMMENT 'from deserializer', 
  `operatingsystem` string COMMENT 'from deserializer', 
  `licensemodel` string COMMENT 'from deserializer', 
  `group` string COMMENT 'from deserializer', 
  `groupdescription` string COMMENT 'from deserializer', 
  `transfertype` string COMMENT 'from deserializer', 
  `fromlocation` string COMMENT 'from deserializer', 
  `fromlocationtype` string COMMENT 'from deserializer', 
  `tolocation` string COMMENT 'from deserializer', 
  `tolocationtype` string COMMENT 'from deserializer', 
  `usagetype` string COMMENT 'from deserializer', 
  `operation` string COMMENT 'from deserializer', 
  `availabilityzone` string COMMENT 'from deserializer', 
  `capacitystatus` string COMMENT 'from deserializer', 
  `classicnetworkingsupport` string COMMENT 'from deserializer', 
  `dedicatedebsthroughput` string COMMENT 'from deserializer', 
  `ecu` string COMMENT 'from deserializer', 
  `elasticgraphicstype` string COMMENT 'from deserializer', 
  `enhancednetworkingsupported` string COMMENT 'from deserializer', 
  `fromregion` string COMMENT 'from deserializer', 
  `gpu` string COMMENT 'from deserializer', 
  `gpumemory` string COMMENT 'from deserializer', 
  `instance` string COMMENT 'from deserializer', 
  `instancecapacity-10xlarge` string COMMENT 'from deserializer', 
  `instancecapacity-12xlarge` string COMMENT 'from deserializer', 
  `instancecapacity-16xlarge` string COMMENT 'from deserializer', 
  `instancecapacity-18xlarge` string COMMENT 'from deserializer', 
  `instancecapacity-24xlarge` string COMMENT 'from deserializer', 
  `instancecapacity-2xlarge` string COMMENT 'from deserializer', 
  `instancecapacity-32xlarge` string COMMENT 'from deserializer', 
  `instancecapacity-4xlarge` string COMMENT 'from deserializer', 
  `instancecapacity-8xlarge` string COMMENT 'from deserializer', 
  `instancecapacity-9xlarge` string COMMENT 'from deserializer', 
  `instancecapacity-large` string COMMENT 'from deserializer', 
  `instancecapacity-medium` string COMMENT 'from deserializer', 
  `instancecapacity-metal` string COMMENT 'from deserializer', 
  `instancecapacity-xlarge` string COMMENT 'from deserializer', 
  `instancesku` string COMMENT 'from deserializer', 
  `intelavxavailable` string COMMENT 'from deserializer', 
  `intelavx2available` string COMMENT 'from deserializer', 
  `intelturboavailable` string COMMENT 'from deserializer', 
  `marketoption` string COMMENT 'from deserializer', 
  `normalizationsizefactor` string COMMENT 'from deserializer', 
  `physicalcores` string COMMENT 'from deserializer', 
  `preinstalleds/w` string COMMENT 'from deserializer', 
  `processorfeatures` string COMMENT 'from deserializer', 
  `producttype` string COMMENT 'from deserializer', 
  `regioncode` string COMMENT 'from deserializer', 
  `resourcetype` string COMMENT 'from deserializer', 
  `servicename` string COMMENT 'from deserializer', 
  `snapshotarchivefeetype` string COMMENT 'from deserializer', 
  `toregioncode` string COMMENT 'from deserializer', 
  `volumeapiname` string COMMENT 'from deserializer', 
  `vpcnetworkingsupport` string COMMENT 'from deserializer')
  ROW FORMAT SERDE 
    'org.apache.hadoop.hive.serde2.OpenCSVSerde' 
  WITH SERDEPROPERTIES ( 
    'escapeChar'='\\', 
    'quoteChar'='\"', 
    'separatorChar'=',') 
  STORED AS INPUTFORMAT 
    'org.apache.hadoop.mapred.TextInputFormat' 
  OUTPUTFORMAT 
    'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
  LOCATION
    's3://${DestinationBucket}/${CFDataName}/ec2'
  TBLPROPERTIES (
    'has_encrypted_data'='false', 
    'skip.header.line.count'='6', 
    'transient_lastDdlTime'='1625832980')"


  RDSLambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub "${CFDataName}-RDS-Lambda-Function"
      Description: !Sub "LambdaFunction to retrieve RDS ${CFDataName}"
      Runtime: python3.8
      Architectures: [arm64]
      Code:
        ZipFile: |
          #Author Stephanie Gooch 2021
          # Function to download RDS pricing
          # Please reachout to costoptimization@amazon.com if there's any comments or suggestions

          import json
          import boto3
          import urllib3
          import urllib.request
          import os
          import logging

          def lambda_handler(event, context):

              s3=boto3.resource('s3')
              http=urllib3.PoolManager()

              url = 'https://pricing.us-east-1.amazonaws.com/offers/v1.0/aws/AmazonRDS/current/index.csv'
              s3Bucket =  os.environ["BUCKET_NAME"]
              key = f'{os.environ["DEST_PREFIX"]}/rds/rds_prices.csv'

              urllib.request.urlopen(url)   #Provide URL
              s3.meta.client.upload_fileobj(http.request('GET', url, preload_content=False), s3Bucket, key)

              return {
                  'statusCode': 200,
                  'body': json.dumps('YAY!')
              }

      Handler: 'index.lambda_handler'
      MemorySize: 2880
      Timeout: 300
      Role:
        Fn::GetAtt:
          - LambdaRole
          - Arn
      Environment:
        Variables:
          BUCKET_NAME:
            !Ref DestinationBucket
          ACCOUNT_ID: AWS::AccountId
          DEST_PREFIX: !Ref CFDataName
  
  AthenaRDSPricingTable:
    Type: AWS::Athena::NamedQuery
    Properties:
      Database: !Ref DatabaseName
      Description: Provides a summary view of the lambda data
      Name: rds_pricing_table
      QueryString: !Sub  
        "CREATE EXTERNAL TABLE rds_pricing(
        sku string, 
        offertermcode string, 
        ratecode string, 
        termtype string, 
        pricedescription string, 
        effectivedate string, 
        startingrange string, 
        endingrange string, 
        unit string, 
        priceperunit string, 
        currency string, 
        relatedto string, 
        leasecontractlength string, 
        purchaseoption string, 
        offeringclass string, 
        productfamily string, 
        servicecode string, 
        location string, 
        locationtype string, 
        instancetype string, 
        currentgeneration string, 
        instancefamily string, 
        vcpu string, 
        physicalprocessor string, 
        clockspeed string, 
        memory string, 
        storage string, 
        networkperformance string, 
        processorarchitecture string, 
        storagemedia string, 
        volumetype string, 
        minvolumesize string, 
        maxvolumesize string, 
        enginecode string, 
        databaseengine string, 
        databaseedition string, 
        licensemodel string, 
        deploymentoption string, 
        group string, 
        groupdescription string, 
        usagetype string, 
        operation string, 
        dedicatedebsthroughput string, 
        enhancednetworkingsupported string, 
        instancetypefamily string, 
        normalizationsizefactor string, 
        processorfeatures string, 
        servicename string)
        ROW FORMAT SERDE
        'org.apache.hadoop.hive.serde2.OpenCSVSerde'
        WITH SERDEPROPERTIES (
        'quoteChar'='\"',
        'separatorChar'=',')
        STORED AS INPUTFORMAT
        'org.apache.hadoop.mapred.TextInputFormat'
        OUTPUTFORMAT
        'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
        LOCATION
        's3://${DestinationBucket}/${CFDataName}/rds'
        TBLPROPERTIES (
        'CrawlerSchemaDeserializerVersion'='1.0',
        'CrawlerSchemaSerializerVersion'='1.0',
        'UPDATED_BY_CRAWLER'='Pricing CSV',
        'areColumnsQuoted'='true',
        'averageRecordSize'='1061',
        'classification'='csv',
        'columnsOrdered'='true',
        'compressionType'='none',
        'delimiter'=',',
        'objectCount'='1',
        'recordCount'='2089892',
        'sizeKey'='2217375799',
        'skip.header.line.count'='6',
        'typeOfData'='file')"